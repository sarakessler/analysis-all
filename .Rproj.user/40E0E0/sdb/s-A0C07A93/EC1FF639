{
    "collab_server" : "",
    "contents" : "---\ntitle: \"R Notebook\"\noutput: html_notebook\n---\n\n```{r}\n#read in data from replication of tribushinina\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(rjson)\nlibrary(ordinal)\nlibrary(coin)\nlibrary(lme4)\n#library(AICcmodavg)\n\nsem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}\nci95 <- function(x) {sem(x) * 1.96}\naddnas <- function (x) {if (length(x)==0){\n  result = NA\n} else {result = x}\n  return(result)\n}\n\n####Import data\n\npath_rep <- \"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/Trib2011-1-rep/\"\nfiles_rep <- dir(\"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/Trib2011-1-rep/anonymized-results\", \n             pattern = \"*.json\")\n\nNUM_TRIALS <- 50\nd.raw.rep <- data.frame()\n\nfor (f in files_rep) {\n  jf <- paste0(path_rep, \"anonymized-results/\",f)\n  jd <- fromJSON(file = jf)\n  id <- data.frame(subid = f,\n                   exp_name = \"rep\",\n                   unique_id = paste0(\"rep_\", f),\n                   adj = jd$answers$data$adj,\n                   verb = jd$answers$data$verb,\n                   noun = jd$answers$data$noun,\n                   dir = jd$answers$data$dir,\n                   num_checked = as.numeric(jd$answers$data$num_checked),\n                   quest_order = c(1:NUM_TRIALS),\n                   noun = jd$answers$data$noun,\n                   elapsed_ms = jd$answers$data$elapsed_ms,\n                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   gender = jd$answers$data$gender,\n                   prototype_status = jd$answers$data$prototype_status,\n                   non_consec = jd$answers$data$non_consecutive,\n                   is_endpoint = jd$answers$data$is_endpoint,\n                   endpoint = as.character(unlist(jd$answers$data$endpoint)),\n                   good_endpoint = jd$answers$data$good_ep,\n                   none_checked = jd$answers$data$none_checked,\n                   screen_size = as.numeric(jd$answers$data$screen_size))\n                    \n                  \n  d.raw.rep <- bind_rows(d.raw.rep, id)\n}\n```\n\n```{r}\n\n#cleans up unpredictable typos in language name\ntable(as.factor(d.raw.rep$language))\nfor (i in 1:length(d.raw.rep$language)) {\n   if (d.raw.rep$language[i] == \"ebglish\" & (!is.na(d.raw.rep$language[i]))){\n   d.raw.rep$language[i] = \"english\"\n   }\n}\nnum_trials = 48\n\n#filters out non native speakers, screens under 12 inches, people with too many non-consecutive or no endpoint trials, and all non-consecutive, no endpoint or wrong endpoint trials.\nd.rep <- filter(d.raw.rep, prototype_status != \"na\") %>%\n  filter(as.numeric(screen_size) >= 12) %>%\n  filter(str_detect(language, 'eng')) %>%\n  select(-language) %>%\n  group_by(subid) %>%\n  mutate(perc_non_consec = sum(non_consec)/num_trials,\n            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,\n         perc_good_endpoint = (sum(good_endpoint))/num_trials) %>%\n  filter(perc_non_consec < .1) %>%\n  filter(perc_good_endpoint >.9) %>%\n  filter(is_endpoint == TRUE) %>%\n  filter(good_endpoint == TRUE) %>%\n  filter(non_consec == FALSE)\nfor (i in 1:length(d.rep$none_checked)) {\n   if (d.rep$none_checked[i] == TRUE & (!is.na(d.rep$none_checked[i]))){\n   d.rep$num_checked[i] = 0\n   }\n }\n\n```\n\n```{r}\n#read in data from Trib2011 replication with ducklings and bunnies\npath_bunny <- \"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/Trib2011-2-bunnies/\"\nfiles_bunny <- dir(\"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/Trib2011-2-bunnies/anonymized-results\", \n             pattern = \"*.json\")\n\nNUM_TRIALS <- 50\nd.raw.bunny <- data.frame()\n\nfor (f in files_bunny) {\n  jf <- paste0(path_bunny, \"anonymized-results/\",f)\n  jd <- fromJSON(file = jf)\n  id <- data.frame(subid = f,\n                   exp_name = \"bunny\",\n                   unique_id = paste0(\"bunny_\", f),\n                   adj = jd$answers$data$adj,\n                   verb = jd$answers$data$verb,\n                   noun = jd$answers$data$noun,\n                   dir = jd$answers$data$dir,\n                   num_checked = as.numeric(jd$answers$data$num_checked),\n                   quest_order = c(1:NUM_TRIALS),\n                   noun = jd$answers$data$noun,\n                   elapsed_ms = jd$answers$data$elapsed_ms,\n                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   gender = jd$answers$data$gender,\n                   prototype_status = jd$answers$data$prototype_status,\n                   non_consec = jd$answers$data$non_consecutive,\n                   is_endpoint = jd$answers$data$is_endpoint,\n                   endpoint = as.character(unlist(jd$answers$data$endpoint)),\n                   good_endpoint = jd$answers$data$good_ep,\n                   none_checked = jd$answers$data$none_checked,\n                   screen_size = as.numeric(jd$answers$data$screen_size))\n                    \n                  \n  d.raw.bunny <- bind_rows(d.raw.bunny, id)\n}\n```\n\n```{r}\n#filters out non native speakers, screens under 12 inches, people with too many non-consecutive or no endpoint trials, and all non-consecutive, no endpoint or wrong endpoint trials.\nd.bunny <- filter(d.raw.bunny, prototype_status != \"na\") %>%\n  filter(as.numeric(screen_size) >= 12) %>%\n  filter(str_detect(language, 'eng')) %>%\n  select(-language) %>%\n  group_by(subid) %>%\n  mutate(perc_non_consec = sum(non_consec)/num_trials,\n            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,\n         perc_good_endpoint = (sum(good_endpoint))/num_trials) %>%\n  filter(perc_non_consec < .1) %>%\n  filter(perc_good_endpoint >.9) %>%\n  filter(is_endpoint == TRUE) %>%\n  filter(good_endpoint == TRUE) %>%\n  filter(non_consec == FALSE)\nfor (i in 1:length(d.bunny$none_checked)) {\n   if (d.bunny$none_checked[i] == TRUE & (!is.na(d.bunny$none_checked[i]))){\n   d.bunny$num_checked[i] = 0\n   }\n }\n```\n\n\n```{r}\n#read in data for reverse tribushinina\npath_rev <- \"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/Rev-Trib/\"\nfiles_rev <- dir(\"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/Rev-Trib/anonymized-results\", \n             pattern = \"*.json\")\n\nNUM_TRIALS <- 50\nd.raw.rev <- data.frame()\n\nfor (f in files_rev) {\n  jf <- paste0(path_rev, \"anonymized-results/\",f)\n  jd <- fromJSON(file = jf)\n  id <- data.frame(subid = f,\n                   exp_name = \"rev\",\n                   unique_id = paste0(\"rev_\", f),\n                   adj = jd$answers$data$adj,\n                   verb = jd$answers$data$verb,\n                   noun = jd$answers$data$noun,\n                   dir = jd$answers$data$dir,\n                   num_checked = as.numeric(jd$answers$data$num_checked),\n                   quest_order = c(1:NUM_TRIALS),\n                   noun = jd$answers$data$noun,\n                   elapsed_ms = jd$answers$data$elapsed_ms,\n                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   gender = jd$answers$data$gender,\n                   prototype_status = jd$answers$data$prototype_status,\n                   non_consec = jd$answers$data$non_consecutive,\n                   is_endpoint = jd$answers$data$is_endpoint,\n                   endpoint = as.character(unlist(jd$answers$data$endpoint)),\n                   good_endpoint = jd$answers$data$good_ep,\n                   none_checked = jd$answers$data$none_checked,\n                   screen_size = as.numeric(jd$answers$data$screen_size))\n                    \n                  \n  d.raw.rev <- bind_rows(d.raw.rev, id)\n}\n\n```\n\n```{r}\n#filters out non native speakers, screens under 12 inches, people with too many non-consecutive or no endpoint trials, and all non-consecutive, no endpoint or wrong endpoint trials.\nd.rev <- d.raw.rev %>%\n  filter(adj !=\"pretty\") %>%\n  filter(adj != \"ugly\")%>%\n  filter(as.numeric(screen_size) >= 12) %>%\n  filter(str_detect(language, 'eng')) %>%\n  select(-language) %>%\n  group_by(subid) %>%\n  mutate(perc_non_consec = sum(non_consec)/num_trials,\n            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,\n         perc_good_endpoint = (sum(good_endpoint))/num_trials) %>%\n  filter(perc_non_consec < .1) %>%\n  filter(perc_good_endpoint >.9) %>%\n  filter(is_endpoint == TRUE) %>%\n  filter(good_endpoint == TRUE) %>%\n  filter(non_consec == FALSE)\nfor (i in 1:length(d.rev$none_checked)) {\n   if (d.rev$none_checked[i] == TRUE & (!is.na(d.rev$none_checked[i]))){\n   d.rev$num_checked[i] = 0\n   }\n }\n```\n\n\n```{r}\n#read in data from three conditions - condition 1 - ordered photographs, condition 2 - random order photographs, condition 3 - random order tiny things\npath_3cond <- \"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/3conditions/\"\nfiles_3cond <- dir(\"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/3conditions/anonymized-results\", \n             pattern = \"*.json\")\n\n\nd.raw.3cond <- data.frame()\n\nfor (f in files_3cond) {\n  jf <- paste0(path_3cond, \"anonymized-results/\",f)\n  jd <- fromJSON(file = jf)\n  if (is.element(1,jd$answers$data$expt_condition)){\n    NUM_TRIALS <- 50\n  } else{\n    NUM_TRIALS <- 26\n  }\n  NUM_TARGETS <- NUM_TRIALS - 2\n  id <- data.frame(subid = f,\n                   exp_name = \"3cond\",\n                   unique_id = paste0(\"3cond_\", f),\n                   condition = jd$answers$data$expt_condition,\n                   number_of_trials = NUM_TRIALS,\n                   number_of_targets = NUM_TARGETS,\n                   adj = jd$answers$data$adj,\n                   verb = jd$answers$data$verb,\n                   noun = jd$answers$data$noun,\n                   dir = as.character(cbind(jd$answers$data$dir)),\n                   num_checked = as.numeric(jd$answers$data$num_checked),\n                   quest_order = c(1:NUM_TRIALS),\n                   elapsed_ms = jd$answers$data$elapsed_ms,\n                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   gender = jd$answers$data$gender,\n                   prototype_status = jd$answers$data$prototype_status,\n                   non_consec = jd$answers$data$non_consecutive,\n                   is_endpoint = jd$answers$data$is_endpoint,\n                   endpoint = as.character(unlist(jd$answers$data$endpoint)),\n                   good_endpoint = jd$answers$data$good_ep,\n                   none_checked = jd$answers$data$none_checked,\n                   all_checked = jd$answers$data$all_checked,\n                   comments = jd$answers$data$expt_gen,\n                   screen_size = as.numeric(jd$answers$data$screen_size))\n                    \n                  \n  d.raw.3cond <- bind_rows(d.raw.3cond, id)\n}\n```\n\n```{r}\n#clean up language typos\ntable(as.factor(d.raw.3cond$language))\nfor (i in 1:length(d.raw.3cond$language)) {\n   if (d.raw.3cond$language[i] == \"rnglish\" & (!is.na(d.raw.3cond$language[i]))){\n   d.raw.3cond$language[i] = \"english\"\n   }\n }\n\n```\n\n```{r}\n#exclude people for language, screen size, too many non-consecutive or no-endpoint trials, and trials with no endpoint or non-consecutive.\nd.3cond <- d.raw.3cond %>%\n  filter(verb == \"are\") %>%\n  filter(adj !=\"pretty\") %>%\n  filter(adj != \"ugly\")%>%\n  filter(as.numeric(screen_size) >= 12) %>%\n  filter(str_detect(language, 'eng')) %>%\n  select(-language) %>%\n  group_by(subid) %>%\n  mutate(perc_non_consec = sum(non_consec)/number_of_targets,\n            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/number_of_targets,\n         perc_good_endpoint = (sum(good_endpoint))/number_of_targets) %>%\n  filter(perc_non_consec < .1) %>%\n  filter(perc_good_endpoint >.9) %>%\n  filter(is_endpoint == TRUE) %>%\n  filter(good_endpoint == TRUE) %>%\n  filter(non_consec == FALSE)\nfor (i in 1:length(d.3cond$none_checked)) {\n   if (d.3cond$none_checked[i] == TRUE & (!is.na(d.3cond$none_checked[i]))){\n   d.3cond$num_checked[i] = 0\n   }\n }\n```\n\n\n```{r}\n#read in norming data. Condition 1 - photos, condition 2 - cartoons, condition 3 - words\npath_norm <- \"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/norming/\"\nfiles_norm <- dir(\"D:/Dropbox/School/more adjs/experiment 1b/analysis-all/norming/anonymized-results/\", \n             pattern = \"*.json\")\nd.raw.norm <- data.frame()\n\nNUM_TRIALS <- 48\n\nfor (f in files_norm) {\n  jf <- paste0(path_norm, \"anonymized-results/\",f)\n  jd <- fromJSON(file = jf)\n  NUM_TARGETS <- NUM_TRIALS\n  id <- data.frame(subid = f,\n                   number_of_trials = NUM_TRIALS,\n                   noun = jd$answers$data$noun,\n                   condition = as.numeric(jd$answers$data$expt_condition),\n                   rating = as.numeric(jd$answers$data$rating),\n                   prototype_status = jd$answers$data$prototype_status,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   gender = jd$answers$data$gender,\n                   comments = jd$answers$data$expt_gen,\n                   screen_size = as.numeric(jd$answers$data$screen_size))\n                    \n                  \n  d.raw.norm <- bind_rows(d.raw.norm, id)\n}\n\ntarget = c('elephant', 'hippo', 'house', 'plane','baby', 'duckling', 'gnome', 'bunny','chick', 'mouse', 'balloon', 'cake', 'monkey', 'umbrella', 'ant', 'bean', 'candy', 'hazelnut', 'earring', 'fly', 'blueberry', 'seed', 'ladybug', 'pill', 'pin', 'tack')\n\nd.raw.norm$type[d.raw.norm$noun %in% target] <- \"targ\"\nd.raw.norm$type[!d.raw.norm$noun %in% target] <- \"control\"\n\n```\n\n```{r}\n#filter out people on very small screens and non-English speakers\nd.norm <- d.raw.norm %>%\n  filter(as.numeric(screen_size) >= 12) %>%\n  filter(str_detect(language, 'eng')) %>%\n  select(-language) %>%\n  group_by(subid)\n```\n\n```{r}\n#exclude participants with more than 6 trials deviating from more than 2 sds from the mean for the prototype status category of the object.\nd_var <- d.norm %>%\n  group_by(prototype_status) %>%\n  summarise(mean = mean(rating), sds = sd(rating))\nd.norm <- d.norm %>%\n  left_join(d_var)%>%\n  mutate(dist = abs((mean - rating)/sds), excl = dist>=2)\n  \n\nd_people <- d.norm %>%\n  group_by(subid)%>%\n  summarise(exclusions = sum(excl)) %>%\n  arrange(exclusions)\n\nd.norm<- d.norm %>%\n  left_join(d_people)\n\nd_noexc <- d.norm%>%\n  filter(exclusions <6)%>%\n  filter(!excl)\n\nlength(unique(d_noexc$workerid))\n\nd.norm.means <- d.norm %>%\n  filter(type==\"targ\")%>%\n  group_by(noun,condition) %>%\n  summarise(mean = mean(rating))\n```\n\n```{r}\nsummary(d.rep)\nd.rep = droplevels(d.rep)\nd.rep$fac_num_checked = as.factor(as.character(d.rep$num_checked))\nmean_size = d.norm.means %>%\n  filter(condition == 2)%>%\n  select(-condition)\nd.rep = d.rep %>%\n  left_join(mean_size,by=c(\"noun\"))\n\nd.rep$noun = as.factor(d.rep$noun)\nd.rep.are = d.rep %>%\n  filter(verb == \"are\")\nm = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1+adj*prototype_status|subid), data=d.rep.are)\n#m = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\nsummary(m)\nsave(m,file = \"m.rda\")\nload(\"m.rda\")\n\n\n#attampts to put together a model that incorporates verb as an effect (are, find, seem)\n#clmm(fac_num_checked ~ adj*prototype_status + verb + dir + quest_order + (1+adj|noun) + (1+adj*prototype_status|subid), data=d.rep) did not converge\nm.allvs.simp = clmm(fac_num_checked ~ adj*prototype_status + verb + dir + quest_order + (1+adj|noun) + (1|subid), data=d.rep)\nsummary(m.allvs.simp)\nsave(m.allvs.simp,file = \"m.allvs.simp.rda\")\nload(\"m.allvs.simp.rda\")\n\n\n#m.simple = clmm(fac_num_checked ~ adj*prototype_status - prototype_status + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\n#summary(m.simple)\n\n\n\nm.norm = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1+adj|subid), data=d.rep.are)\nsummary(m.norm)\nsave(m.norm,file = \"m.norm.rda\")\nload(\"m.norm.rda\")\n#doesn't converge, also didn't converge with just adj as a slope for subid\n#m.norm1 = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1+adj*mean|subid), data=d.rep.are)\n#summary(m.norm1)\n\nm.allvs.simp.norm = clmm(fac_num_checked ~ adj*mean + verb + dir + quest_order + (1+adj|noun) + (1|subid), data=d.rep)\nsummary(m.allvs.simp.norm)\nsave(m.allvs.simp.norm,file = \"m.allvs.simp.norm.rda\")\nload(\"m.allvs.simp.norm.rda\")\n#m.simple = clmm(fac_num_checked ~ adj*mean - mean + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\n#summary(m.simple)\n```\n\n```{r}\nsummary(d.rev)\nd.rev = droplevels(d.rev)\nd.rev$fac_num_checked = as.factor(as.character(d.rev$num_checked))\n\nm.rev = clmm(fac_num_checked ~ adj + dir + quest_order + (1+adj|noun) + (1+adj|subid), data=d.rev)\n#m = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\nsummary(m.rev)\nsave(m.rev,file = \"m.rev.rda\")\nload(\"m.rev.rda\")\n\n\n\n#m.simple = clmm(fac_num_checked ~ adj*prototype_status - prototype_status + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\n#summary(m.simple)\n\nmean_size = d.norm.means %>%\n  filter(condition == 1)%>%\n  select(-condition)\nd.rev = d.rev %>%\n  left_join(mean_size,by=c(\"noun\"))\n\nm.rev.norm = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1+adj|subid), data=d.rev)\nsummary(m.rev.norm)\nsave(m.rev.norm,file = \"m.rev.norm.rda\")\nload(\"m.rev.norm.rda\")\n\nm.rev.norm1 = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1|subid), data=d.rev)\nsummary(m.rev.norm1)\nsave(m.rev.norm1, file = \"m.rev.norm1.rda\")\nload(\"m.rev.norm1.rda\")\n\n#m.simple = clmm(fac_num_checked ~ adj*mean - mean + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\n#summary(m.simple)\n```\n\n```{r}\nsummary(d.3cond)\nd.3cond = droplevels(d.3cond)\nd.3cond$fac_num_checked = as.factor(as.character(d.3cond$num_checked))\n\nmean_size = d.norm.means %>%\n  filter(condition == 2)%>%\n  select(-condition)\nd.3cond = d.3cond %>%\n  left_join(mean_size,by=c(\"noun\"))\n\nd.3cond.ordphot = d.3cond %>%\n  filter(condition == 1)\n\nm.ordphot = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1+adj*prototype_status|subid), data=d.3cond.ordphot)\nsummary(m.ordphot)\nsave(m.ordphot,file = \"m.ordphot.rda\")\nload(\"m.ordphot.rda\")\n\n#also does not converge\n#m.ordphot1 = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1+adj|subid) + (0+prototype_status|subid) + (0+adj:prototype_status|subid), data=d.3cond.ordphot, verbose=TRUE)\n#summary(m.ordphot1)\n#save(m.ordphot1,file = \"m.ordphot1.rda\")\n#load(\"m.ordphot1.rda\")\n#since the other one gives NAs instead of stats I'm going to try simplifying the random effects\nm.ordphot.simp = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1+adj|subid), data=d.3cond.ordphot)\nsummary(m.ordphot.simp)\nsave(m.ordphot.simp,file = \"m.ordphot.simp.rda\")\nload(\"m.ordphot.simp.rda\")\n\n\nd.3cond.ranphot = d.3cond %>%\n  filter(condition == 2)\nm.ranphot = clmm(fac_num_checked ~ adj*prototype_status + quest_order + (1+adj|noun) + (1+adj*prototype_status|subid), data=d.3cond.ranphot)\nsummary(m.ranphot)\nsave(m.ranphot,file = \"m.ranphot.rda\")\nload(\"m.ranphot.rda\")\n\nd.3cond.rantiny = d.3cond %>%\n  filter(condition == 3)\nm.rantiny = clmm(fac_num_checked ~ adj + quest_order + (1+adj|noun) + (1+adj|subid), data=d.3cond.rantiny)\nsummary(m.rantiny)\nsave(m.rantiny,file = \"m.rantiny.rda\")\nload(\"m.rantiny.rda\")\n\n\n\nm.ordphot.norm = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1+adj|subid), data=d.3cond.ordphot)\nsummary(m.ordphot.norm)\nsave(m.ordphot.norm,file = \"m.ordphot.norm.rda\")\nload(\"m.ordphot.norm.rda\")\n\nm.ranphot.norm = clmm(fac_num_checked ~ adj*mean + quest_order + (1+adj|noun) + (1+adj|subid), data=d.3cond.ranphot)\nsummary(m.ranphot.norm)\nsave(m.ranphot.norm, file = \"m.ranphot.norm.rda\")\nload(\"m.ranphot.norm.rda\")\n\nm.rantiny.norm = clmm(fac_num_checked ~ adj*mean + quest_order + (1+adj|noun) + (1+adj|subid), data=d.3cond.rantiny)\nsummary(m.rantiny.norm)\nsave(m.rantiny.norm,file =\"m.rantiny.norm.rda\")\nload(\"m.rantiny.norm.rda\")\n\n#other version of random effects structure with interaction between adjective and mean (is that a thing?) -only the third one converged\n# m.ordphot.norm1 = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1+adj*mean|subid), data=d.3cond.ordphot)\n# summary(m.ordphot.norm1)\n# \n# m.ranphot.norm1 = clmm(fac_num_checked ~ adj*mean + quest_order + (1+adj|noun) + (1+adj*mean|subid), data=d.3cond.ranphot)\n# summary(m.ranphot.norm1)\n\nm.rantiny.norm1 = clmm(fac_num_checked ~ adj*mean + quest_order + (1+adj|noun) + (1+adj*mean|subid), data=d.3cond.rantiny)\nsummary(m.rantiny.norm1)\nsave(m.rantiny.norm1,file = \"m.rantiny.norm1.rda\")\nload(\"m.rantiny.norm1.rda\")\n\n\n\n```\n```{r}\n#Models for all experiments with factors releveled so that small is the base.\nd.rep$protr<- d.rep$prototype_status %>%\n  relevel(\"small\")\nd.rep.are <- d.rep %>%\n  filter(verb == \"are\")\n\nd.3cond.ordphot$protr <- as.factor(d.3cond.ordphot$prototype_status) %>%\n  relevel(\"small\")\nd.3cond.ranphot$protr <- as.factor(d.3cond.ranphot$prototype_status) %>%\n  relevel(\"small\")\n\nm.relev = clmm(fac_num_checked ~ adj*protr + dir + quest_order + (1+adj|noun) + (1+adj*protr|subid), data=d.rep.are)\n\nsummary(m.relev)\nsave(m.relev,file = \"m.relev.rda\")\nload(\"m.relev.rda\")\n\n\nm.allvs.simp.relev = clmm(fac_num_checked ~ adj*protr + verb + dir + quest_order + (1+adj|noun) + (1|subid), data=d.rep)\nsummary(m.allvs.simp.relev)\nsave(m.allvs.simp.relev,file = \"m.allvs.simp.relev.rda\")\nload(\"m.allvs.simp.relev.rda\")\n\nm.ordphot.relev = clmm(fac_num_checked ~ adj*protr + dir + quest_order + (1+adj|noun) + (1+adj*protr|subid), data=d.3cond.ordphot)\nsummary(m.ordphot.relev)\nsave(m.ordphot.relev,file = \"m.ordphot.relev.rda\")\nload(\"m.ordphot.relev.rda\")\n\n\n#since the other one gives NAs instead of stats I'm going to try simplifying the random effects\nm.ordphot.simp.relev = clmm(fac_num_checked ~ adj*protr + dir + quest_order + (1+adj|noun) + (1+adj|subid), data=d.3cond.ordphot)\nsummary(m.ordphot.simp.relev)\nsave(m.ordphot.simp.relev,file = \"m.ordphot.simp.relev.rda\")\nload(\"m.ordphot.simp.relev.rda\")\n\n\nm.ranphot.relev = clmm(fac_num_checked ~ adj*protr + quest_order + (1+adj|noun) + (1+adj*protr|subid), data=d.3cond.ranphot)\nsummary(m.ranphot.relev)\nsave(m.ranphot.relev,file = \"m.ranphot.relev.rda\")\nload(\"m.ranphot.relev.rda\")\n\n\n```\n\n```{r}\n#Original code from Judith meeting\nsummary(d)\nd = droplevels(d)\nd$fac_num_checked = as.factor(as.character(d$num_checked))\nm = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1+adj*prototype_status|subid), data=d)\nm = clmm(fac_num_checked ~ adj*prototype_status + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\nsummary(m)\n\nm.simple = clmm(fac_num_checked ~ adj*prototype_status - prototype_status + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\nsummary(m.simple)\n\nmean_size = read.csv(\"D:/Dropbox/School/more\\ adjs/experiment\\ 1b/norming/means-cartoons.csv\") %>%\n  select(-condition)\nd = d %>%\n  left_join(mean_size,by=c(\"noun\"))\n\nm = clmm(fac_num_checked ~ adj*mean + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\nsummary(m)\n\nm.simple = clmm(fac_num_checked ~ adj*mean - mean + dir + quest_order + (1+adj|noun) + (1|subid), data=d)\nsummary(m.simple)\n```\n\n",
    "created" : 1529614714305.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2064377817",
    "id" : "EC1FF639",
    "lastKnownWriteTime" : 1531951147,
    "last_content_update" : 1531951147785,
    "path" : "D:/Dropbox/School/more adjs/experiment 1b/analysis-all/all-analysis.Rmd",
    "project_path" : "all-analysis.Rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}