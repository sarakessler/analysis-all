{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Trib2011-Analysis\"\nauthor: \"Sara Kessler\"\ndate: \"February 26, 2017\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n\n```\n\n```{r}\nsetwd(\"D:/Dropbox/School/2016-2017/psych254/Tribushinina2011\")\nlibrary(tidyverse)\nlibrary(langcog) \nlibrary(rjson)\n\nsem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}\nci95 <- function(x) {sem(x) * 1.96}\naddnas <- function (x) {if (length(x)==0){\n  result = NA\n} else {result = x}\n  return(result)\n}\n\n```\n\n```{r}\npath <- \"D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/experiment/\"\nfiles <- dir(\"D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/experiment/pilota_results/\", \n             pattern = \"*.json\")\nd.raw <- data.frame()\n\nfor (f in files) {\n  jf <- paste0(path, \"pilota_results/\",f)\n  jd <- fromJSON(file = jf)\n  id <- data.frame(subid = f,\n                   adj = jd$answers$data$adj,\n                   verb = jd$answers$data$verb,\n                   noun = jd$answers$data$noun,\n                   dir = jd$answers$data$dir,\n                   num_checked = as.numeric(jd$answers$data$num_checked),\n                   noun = jd$answers$data$noun,\n                   elapsed_ms = jd$answers$data$elapsed_ms,\n                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   prototype_status = jd$answers$data$prototype_status,\n                   non_consec = addnas(jd$answers$data$non_consecutive),\n                   is_endpoint = addnas(jd$answers$data$is_endpoint),\n                   endpoint = addnas(jd$answer$data$endpoint),\n                   good_endpoint = addnas(jd$answers$data$good_ep),\n                   none_checked = addnas(jd$answer$data$none_checked))\n                    \n                  \n  d.raw <- bind_rows(d.raw, id)\n}\n\n# Number of participants\nlength(unique(d.raw$workerid))\nlength(unique(d.raw$subid))\n\nnum_trials = 48\n\n```\n```{r}\n# get rid of training items, and language columns\n\nd <- filter(d.raw, prototype_status != \"na\") %>%\n  filter(verb == \"find\") %>%\n  #filter(language == \"english\") %>%\n  #select(-language) %>%\n  group_by(subid) %>%\n  mutate(perc_non_consec = sum(non_consec)/num_trials,\n            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,\n         perc_good_endpoint = (sum(good_endpoint))/num_trials) %>%\n  filter(perc_non_consec < .1) %>%\n  filter(perc_good_endpoint >.9) %>%\n  filter(good_endpoint == false) %>%\n  filter(non_consec == true) %>%\n  filter(is_endpoint == false)\n  \nif (d$none_checked == true){\n  d$num_checked = 0\n}\n#need to check for having more than 10% non_consecutive or less than 90% with the right endpoint, and exclude those participants, and then exclude any remaining trials in which there is non_consecutive data or no endpoint.  (The option for saying none of them is big is coded as 9, so that if someone checks both the none box and one of the images then it comes up as non-consecutive)\n\nhead(d)\n```\n\n\n\n```{r}\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))\n```\n```{r}\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(.~dir)\n\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(.~adj)\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(.~verb)\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(.~noun)\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(.~prototype_status)\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(adj~verb)\nqplot(num_checked, data = d, binwidth=1) + \n  xlim(c(1,8))+ facet_grid(adj~prototype_status)\n```\n```{r}\nggplot(d, aes(x = adj, y = num_checked, col = verb)) + \n  geom_jitter() + \n  geom_smooth() +\n  facet_wrap(~prototype_status)\n```\n```{r}\n#test of effects of scale direction. Is this the right test? she doesn't say\nd_zone_dir <- d %>%\n  group_by(subid, noun, adj, dir)%>%\n  summarise(zone = num_checked) %>%\n  spread(dir, zone)\n\nwilcox.test(d_zone_dir$asc, d_zone_dir$desc, paired = TRUE)\n```\n\n\n```{r}\n#testing whether the small zone is bigger than the big zone\nd %>%\n  group_by(verb, adj) %>%\n  summarise(mean_zone = mean(num_checked), sds = sd(num_checked))\n\nd_wilc <- d %>%\n  group_by(subid, verb, noun, adj, dir) %>%\n  summarise(zone = num_checked)%>%\n  spread(adj, zone)\n  wilcox.test(d_wilc$big, d_wilc$small, alternative = \"l\", paired = TRUE)\n```\n\n\n```{r}\nd_graph <- d %>%\n  group_by(prototype_status, adj) %>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n\n\n\ntable(d_graph$adj, d_graph$prototype_status)\nstr(d_graph)\n\nd_graph$adj <- factor(d_graph$adj)\nd_graph$prototype_status <- factor(d_graph$prototype_status)\nlevels(d_graph$prototype_status)\n\nlevels(d_graph$adj)\nlevels(d_graph$prototype_status)\n\n\nfriedman.test(zone ~ adj | prototype_status, data = d_graph)\n\nggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-sems, ymax=mean_zone+sems),\n                  width=.2, position=position_dodge(.9))\n\nggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n```\n\n```{r}\n# Friedman test of differences between objectss of different prototypicality status when the adjective is big\nd_fried <- d %>%\n  filter(adj==\"big\")%>%\n  group_by(subid, prototype_status) %>%\n  summarise(zone = mean(num_checked))\n\n\n\ntable(d_fried$subid, d_fried$prototype_status)\nstr(d_fried)\n\nd_fried$subid <- factor(d_fried$subid)\nd_fried$prototype_status <- factor(d_fried$prototype_status)\nlevels(d_fried$prototype_status)\n\nlevels(d_fried$subid)\nlevels(d_fried$prototype_status)\n\n\nfriedman.test(zone ~ prototype_status  | subid, data = d_fried)\n```\n\n\n```{r}\n#test the difference between prototypically big and neutral objects when the adjective is big\nd_wilc_bn <- d %>%\n  filter(adj == \"big\")%>%\n  filter(prototype_status != \"small\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_bn$big, d_wilc_bn$neither, alternative = \"l\", paired = TRUE)\n```\n\n```{r}\n#test the difference between prototypically neither and small objects when the adjective is big\nd_wilc_ns <- d %>%\n  filter(adj == \"big\")%>%\n  filter(prototype_status != \"big\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_ns$neither, d_wilc_ns$small, alternative = \"l\", paired = TRUE)\n```\n\n```{r}\n#test the difference between prototypically big and small objects when the adjective is big\nd_wilc_bs <- d %>%\n  filter(adj == \"big\")%>%\n  filter(prototype_status != \"neither\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_bs$big, d_wilc_bs$small, alternative = \"l\", paired = TRUE)\n```\n\n```{r}\n# Friedman test of differences between objectss of different prototypicality status when the adjective is small\nd_fried_s <- d %>%\n  filter(adj==\"big\")%>%\n  group_by(subid, prototype_status) %>%\n  summarise(zone = mean(num_checked))\n\n\n\ntable(d_fried_s$subid, d_fried_s$prototype_status)\nstr(d_fried_s)\n\nd_fried_s$subid <- factor(d_fried_s$subid)\nd_fried_s$prototype_status <- factor(d_fried_s$prototype_status)\nlevels(d_fried_s$prototype_status)\n\nlevels(d_fried$subid)\nlevels(d_fried$prototype_status)\n\n\nfriedman.test(zone ~ prototype_status  | subid, data = d_fried_s)\n```\n\n\n```{r}\n#test the difference between prototypically big and neutral objects when the adjective is small\nd_wilc_sbn <- d %>%\n  filter(adj == \"small\")%>%\n  filter(prototype_status != \"small\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_sbn$big, d_wilc_sbn$neither, alternative = \"l\", paired = TRUE)\n```\n\n```{r}\n#test the difference between prototypically neither and small objects when the adjective is small\nd_wilc_sns <- d %>%\n  filter(adj == \"small\")%>%\n  filter(prototype_status != \"big\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_sns$neither, d_wilc_sns$small, alternative = \"l\", paired = TRUE)\n```\n\n```{r}\n#test the difference between prototypically big and small objects when the adjective is small\nd_wilc_sbs <- d %>%\n  filter(adj == \"small\")%>%\n  filter(prototype_status != \"neither\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_sbs$big, d_wilc_sbs$small, alternative = \"l\", paired = TRUE)\n```\n\n\n```{r}\nd_graph <- d %>%\n  group_by(prototype_status, adj) %>%\n  summarise(mean_rt = mean(elapsed_first_click_ms), sems = sem(elapsed_first_click_ms), cis = ci95(elapsed_first_click_ms))\n\n\n\nd_graph$adj <- factor(d_graph$adj)\n\n\nlevels(d_graph$adj)\n\n\nggplot(d_graph, aes(x=adj, y=mean_rt, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_rt-sems, ymax=mean_rt+sems),\n                  width=.2, position=position_dodge(.9))\n\nggplot(d_graph, aes(x=adj, y=mean_rt, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_rt-cis, ymax=mean_rt+cis),\n                  width=.2, position=position_dodge(.9))\n```\n\n\n```{r}\n#test the difference between RTs for prototypically big when the adjective is small and prototypically small objects when the adjective is big -- incompatible questions\n\n\nsmall_incomp <- d %>%\n  filter(adj == \"small\") %>%\n  filter(prototype_status == \"big\")\n\nbig_comp <- d %>%\n  filter(adj == \"big\") %>%\n  filter(prototype_status == \"big\")\n\nbig_incomp <- d %>%\n  filter(adj == \"big\") %>%\n  filter(prototype_status == \"small\")\n\nsmall_comp <- d %>%\n  filter(adj == \"small\") %>%\n  filter(prototype_status == \"small\") \nstr(small_comp)\n\nwilcox.test(small_comp$elapsed_first_click_ms, small_incomp$elapsed_first_click_ms, alternative = \"g\", paired = TRUE)\n\nwilcox.test(big_comp$elapsed_first_click_ms, big_incomp$elapsed_first_click_ms, alternative = \"g\", paired = TRUE)\n\n```\n\n\n\n\n```{r}\n#test of difference between RTs on ascending and descending trials with the same adjective\nd_rt_small <- d %>%\n  filter(adj == \"small\") %>%\n  group_by(subid, noun, dir)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(dir, rt)\n\nwilcox.test(d_rt_small$asc, d_rt_small$desc, alternative = \"l\", paired = TRUE)\n\nd_rt_big <- d %>%\n  filter(adj == \"big\") %>%\n  group_by(subid, noun, dir)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(dir, rt)\n\nwilcox.test(d_rt_big$asc, d_rt_big$desc, alternative = \"l\", paired = TRUE)\n```\n\n\n```{r}\n#test differnece between RTs for the adjective big and the adjective small, with the prediction that the processing of small is more cognitively demanding and therefore RTs should be longer. Tribushinina(2011) did not find a significant differnce.\nd_rt <- d %>%\n  group_by(subid, noun, dir, adj)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(adj, rt)\n\nwilcox.test(d_rt$small, d_rt$big, alternative = \"g\", paired = TRUE)\n```\n\n```{r}\n#test of difference between RTs on ascending and descending trials with the same adjective. Tribushinina (2011) found an effect of scale direction in the case of small, but not big.\nd_rt_small <- d %>%\n  filter(adj == \"small\") %>%\n  group_by(subid, noun, dir)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(dir, rt)\n\nwilcox.test(d_rt_small$asc, d_rt_small$desc, alternative = \"l\", paired = TRUE)\n\nd_rt_big <- d %>%\n  filter(adj == \"big\") %>%\n  group_by(subid, noun, dir)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(dir, rt)\n\nwilcox.test(d_rt_big$asc, d_rt_big$desc, alternative = \"l\", paired = TRUE)\n```",
    "created" : 1530299134607.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2247459292",
    "id" : "4DEDE3CA",
    "lastKnownWriteTime" : 1489458523,
    "last_content_update" : 1489458523,
    "path" : "D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/experiment/experiment-analysis.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}