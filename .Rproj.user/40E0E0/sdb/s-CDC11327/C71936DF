{
    "collab_server" : "",
    "contents" : "---\ntitle: Replication of \"Once more on norms and comparison classes\" by Tribushinina\n  (2011, Linguistics)\nauthor: \"Elena Tribushinina (E.Tribushinina@uu.nl)\"\ndate: 'null'\noutput:\n  pdf_document:\n    toc: yes\n    toc_depth: '4'\n  html_document:\n    toc: yes\n    toc_depth: 4\n    toc_float:\n      collapsed: no\n---\n\n##Introduction\n\nRelative adjectives such as *big* and *small* are context sensitive. The sentence *Timmy is tall* might be judged as true when the context contains 4'9'' Timmy and the rest of his third grade, but false when the context contains Timmy and his three grown siblings. In these two contexts, Timmy's height is being compared to different sets of objects, known as comparison classes. While it has been established that comparison classes are determined by the context, which can manifest both linguistically and extra-linguistically, how exactly the process of forming a representation of a context class occurs, and what type of information goes into these judgments is not settled. Tribushinina (2011) argues that in forming a representation of a comparison class speakers integrate world knowledge with the information they get from the visual context in front of them, operationalized as the pictures displayed in an experimental context.\n\nThe stimuli seen were pictures of objects. All the pictures were smaller than the objects of the type depicted in them generally are. Therefore, if participants were using only prior world knowledge about the typical size of these objects, then all of the images should have counted as small. If participants were using only the information from the visual context, then the same number of items should count as big and small, and that number should not differ by object. If, instead, people integrate both these types of knowledge when forming a comparison class, then the mean number of items counted as *small* is predicted to be bigger than the number counted as *big*, and it more prototypically big items ate predicted to count as *small*, and vice versa.\n\n\n##Methods\nTribushinina had 20 adults do a scalar judgment task. Participants were shown a display of seven items identical except for size, ordered by size, ranging from 1-7 cm in 1 cm increments. There were twelve items shown, four prototypically big (plane, house, elephant, hippo), four prototypically small (chick, baby, mouse, gnome), and four neither prototypically big nor prototypically small (umbrella, balloon, monkey, cake). With each display the participants heard the sentences \"Which X do you find big/small\" (in Dutch), and were allowed  to select as many or as few items as they wanted. The displays were either ascending (increasing in size from left to right) or descending (increasing in size from right to left). Each item was seen four times, with each adjective, and in each direction, for a total of 48 trials. Additionally there were two pretest items, to introduce the task and make people comfortable with choosing as many items as they want. The pre-trial items were \"Which balloons do you find pretty\" and \"Which cars do you find ugly?\".\n\n###Power Analysis\n\nThe original effect size was calculated using the formula for Cohen's d: $\\frac{m_1-m_2}{SD_{pooled}}$. The $SD_{pooled}$ was calculated using the formula $\\sqrt{\\frac{SD_1^2 + SD_2^2}{2}}$. \n```{r}\nSD_1 = 0.9\nSD_2 = 1.3\nSD_p = sqrt((SD_1^2 + SD_2^2)/2)\nm_1 = 2.6\nm_2 = 1.65\nc_d = (m_1 - m_2)/SD_p\nc_d\n\n```\n A G-power power analysis for a-priori sample size results in a required sample size of 11, 14 or 18 participants for 80%, 90% and 95% respectively. I propose to run 2.5 times the number of participants from the original study, for n = 50.\n \n![Power analysis for 80% power](figures/80-percent-screenshot.png)\n\n![Power analysis for 90% power](figures/90-percent-screenshot.png)\n\n![Power analysis for 95% power](figures/95-percent-screenshot.png)\n\n\n\n\n###Planned Sample\n\nI plan to run 50 participants. I will filter these so as to only include native speakers of English. This status will be determined by asking each participant to enter their native language, and excluding those participants who enter something other than English. Since it is a text-box, the data may require cleanup to correct for obvious typos before processing. \n\n\n###Materials and Procedure\n(These sections are together in the original paper)\n\n>Experiment 1 involved a Scalar Judgment Task (Smith et al. 1986, 1988; Syrett et al. 2006; Syrett 2007). The subjects saw pictures of seven same-kind objects on a computer screen and\nheard a question of the type *Welke X vind je groot/klein?* 'Which X do you\nfind big/small', where X was the name of an object category in plural. On the\ndescending trials, the test pictures incrementally decreased in vertical size\nfrom 7-1 cm at one centimeter intervals. On the ascending trials, the pictures\nincreased in vertical size from 1-7 cm at one centimeter intervals (see Figure\n1).\nThree experimental categories were included in this study: prototypically\nbig entities (elephants, hippos, houses, planes), prototypically small entities\n(babies, chickens, gnomes, mice) and prototype-neutral entities that are not\nparticularly associated with either *groot* 'big' or *klein* 'small' (balloons, cakes,\nmonkeys, umbrellas). The selection of test objects was made on the basis of\nthe previous studies that established which objects are seen as prototypically\nbig and small in the Dutch culture (Tribushinina 2008b, 2011). Prototype neutral objects\nwere selected on the basis of two criteria - 1. they are not unequivocally associated\nwith either *groot* 'big' or *klein* 'small'; and 2. they are equally often dubbed *groot* and *klein* by adults in the Dutch corpora (Corpus of Spoken Dutch, Groningen Corpus, Van Kampen Corpus). It is important to notice that prototypicality is a matter of culturally determined construals rather than objective properties of objects. For instance, entities that are known to be best exemplars of smallness are not necessarily smaller than\nprototype-neutral entities. What matters is that certain objects are assigned\nthe status of best exemplars within a particular language/culture. The effects\nof such best exemplars in language use and language development proved\nrobust (Tribushinina 2008b, 2009a, 2011). This experiment aims to determine\nwhether prototypicality effects qua best exemplars also affect adults' scalar\njudgments.\nEach of the 12 object categories was presented in four types of trials: *groot*-descending,\n*groot*-ascending, *klein*-descending, *klein*-ascending (cf. Smith\net al. 1986). This produced the total of 48 experimental trials.\nThe subjects were tested individually in a quiet room. The experiment\nstarted with two pre-test items. The subjects first saw a picture of eleven balloons\nof different colors and answered the question *Welke ballonnen vind je mooi?* 'Which balloons do you find pretty?' After that, they saw a picture of six\ncars and answered the question *Welke auto's vind je lelijk?* 'Which cars do you\nfind ugly?' During the pre-test phase, the participants were instructed to point\nto the objects on the screen if they thought an object could be assigned the corresponding\nproperty. They were also informed that there was no upper or lower\nbound: they were allowed to point to *all* the objects or to *none* of them, if they\nfound appropriate. After the completion of the pre-test phase, the subjects were\npresented with the experimental trials, which were pseudorandomized with\nrespect to two factors: the side of the relevant pole (left or right) and the adjective\n(*groot* or *klein*). Prerecorded audio stimuli (e.g., *Welke olifanten vind je\nklein?* 'Which elephants do you find small?') were automatically presented\nimmediately after the corresponding visual stimulus appeared on the screen.\nTo keep the scalar judgment process as natural as possible, the subjects were\nnot instructed to make speeded judgments.\nThe experimental sessions were videotaped using a JVC Everio Camcorder\nand later analyzed using ELAN 3.8.1 software. Two analyses of the data were\nconducted. The first is an analysis of the ranges dubbed *groot* 'big' and *klein*\n'small' across the three conditions - prototypically big entities, prototypically\nsmall entities and prototype-neutral entities (offline measure). The second is an\nanalysis of RTs during the scalar judgment process (online measure).\n\nI used the original materials. However, a number of manipulations were necessary. I made a couple of adaptations to the pre-test items, aligning the number of options with the rest of the experiment for ease of coding. The other adaptation I made was to the sizing of the stimuli. The original materials has a picture containing all seven images of the display. I took the biggest image of each set, made sure it was sized to 7 cm, and then decreased the size incrementally be a cm each time. The images were then also resized proportionally in the experimental display to fit the size of the participants' screens. Their size relative to each other remains the same.\n\n###Procedure\t\n\nThe original experiment was conducted in the lab, and had people point to the pictures, and recorded their choices on video. Since my replication is being conducted on Mechanical Turk, a number of adaptations were necessary. The first adaptation is that people click on the pictures to select them rather than point at them. This renders video collection unnecessary. Additionally, the replication uses English instead of Dutch. The effect found is predicted to be present regardless of the language. I recorded my stimuli using an automatic text-to-speech generator (https://text-to-speech-demo.mybluemix.net/), in order to preserve consistent prosody across the stimuli, as opposed to the original stimuli which were recorded by a person. I measured reaction times from the onset of the adjective until the first click on a checkbox, as opposed to the original measurement of until the first pointing move. My experiment can be found at:\nhttp://stanford.edu/~skessler/trib2011_rep/study1.html\n\n###Analysis Plan\n\nThe original study looked at peoples pointing gestures. Due to the clicking nature of my task, I will institute a policy regarding the possible ways people could try to game my experiment. There are two unexpected patterns to look for in the data. The first is non-continuous answer sets. If participants, in answering the question *Which balloons do you find small?* select the smallest and then the third and fourth, skipping the second balloon, this is an indication that either they were not paying attention, or that they are not doing the task. I propose to exclude all trials in which there are non-continuous answers (this seems safer than trying to guess which was the reason and filling in the seemingly missing data points),  and exclude any participant who made this mistake on more than 10% of the trials. The second unexpected pattern is answer sets with no endpoint. If a participant did not select the biggest item as *big* but did select other items, it seems possible to be caused by either off the reasons above. I thus propose a similar policy, of excluding all trials with no endpoint and excluding any participant who gave such answers for more than 10% of the trials. Neither of these exclusions are brought up in the original paper, but I think that due to the differences between the laboratory setting and the Mechanical Turk setup, safeguards to gaming the experiment should be instituted.\n\nThe key statistical test in this experiment is the Wilcoxon signed rank test showing that \"the zone labeled *klein* was significantly larger than the *groot* zone: Z = 3.1, p < .005. This finding corroborates the hypothesis that subjects compute norms using, at least, two kinds of information - a contextually given comparison class (i.e., visually presented series) and their world knowledge of average object sizes in reality.\"\n\nAdditionally,  I will test the differences in mean number of items counted as *big* and *small* for items of each prototype status, using a Freidman test for the overall differences between conditions and then pair-wise Wilcoxon tests for between big and neutral, neutral and small, and big and small objects for each adjective. The prediction is that the *big* zone is bigger for prototypically small objects, and smallest for prototypically big objects, and conversely for the *small* zone. The intuition is that you have to be bigger to count as a *big* big thing than as a *big* small thing.\n\nFinally, I will analyze the reaction times (RTs). The finding in Tribushinina (2011) was \n\n>\"Although reactions to prototype-incompatible questions (e.g., Which elephants\ndo you find small? / Which mice do you find big?) took slightly longer\nthan reactions to prototype-compatible questions (e.g., Which elephants do you\nfind big? / Which mice do you find small?), the difference was only significant\nfor *groot*: Z = 2.7, p < .05, but not for *klein*: p = .12 (Wilcoxon Singed-ranks\ntest).\"\n\nAdditionally, Tribushinina tested whether the RTs for the adjective *small* were different than for *big*, with the prediction that the former has greater cognitive complexity and therefore should take longer to process, however no effect was found. Then she tested whether there was an effect of scale direction and found that there was a difference between ascending and descending trials in the case of *small* but not in the case of *big* suggesting that this might be an expression of the greater cognitive complexity of *small*.\n\n  \n\n###Differences from Original Study\n\nThe original study was run in a laboratory setting. The participants saw the images on a screen and pointed to select. This gave them the option of not pointing in order to select none. The participants were recorded in video, and the video was analyzed for the RT measures, and to code their selections.\n\nMy replication differs in setting. It will be conducted on Mechanical Turk. Whereas in the lab, it was known that all participants saw the same exact images, in the replication each participant has a screen of different size, so that the images might be of different actual sizes. However, the relative size of the images to each other, and the images across trials should be preserved, so it should not have an effect of the results. However, I will exclude participants who self report that they did the task on a mobile phone or tablet (screen_size smaller than 12 inches). The change in setting also necessitates additional exclusion criteria. Since there is no experimenter present, it is necessary to ensure that participants were not clicking at random. Additionally, since they are clicking and not pointing, it is easy to not be paying close attention, and think you clicked on an image, without it registering. Therefore, I will exclude all trials in which a no-consecutive set of images was selected, and all trials in which no endpoint was selected, or the incorrect endpoint was selected (e.g., if the question was which are big, and the smallest image was selected, but not the biggest). I will also exclude participants who had more than 10% of their trials excluded for any of the above three reasons.\n\nMy replication also differs in language. The original experiment was conducted in Dutch. However, these adjectives are very similar in the two languages, and the theory does not predict that there should be any difference with respect to  the effect under investigation.\n\n\n### Methods Addendum (Post Data Collection)\n\nI did not change any of the methods between piloting and data collection. However, I did catch a javascript bug where when the participant selected the option that none of the pictures were *big/small* the endpoint wasn't being saved, and therefore the function to check if the endpoint was good wasn't working. Therefore in pilot B I did not filter out participants by whether they marked a good endpoint. Additionally, since there weren't very many participants for pilot B I did not separate out the results for the different verbs. The results reported here are only for the verb *find* ('Which Xs do you find big/small'), which is the closest English equivalent of the original Dutch question.\n\n#### Actual Sample\nWith the filtering conditions set up the way they were, I ended up with an n = 35. This is substantially less than the planned n = 50, but still higher than the original study and sufficiently powered.\n\n#### Differences from pre-data collection methods plan \n I added code to correct an unpredicted typo of \"Ebglish\" for \"English\", so that that participant was not excluded. The participants that entered \"e\" for their native language, as well as the one who entered \"yes\" were excluded. \n \n I also found a copy-paste error in the Wilcoxon tests testing the difference between the mean number of items checked for each pair of prototypicality statuses with the adjective \"small\" I was testing whether the zone for prototypically small items was bigger than the zone for neutral or big items, when actually I intended to test the other direction, which would match what Tribushinina predicted and found. This was corrected in the analysis code during data analysis.\n\n\n##Results\n\n\n### Data preparation\n\nData preparation following the analysis plan.\n\t\n```{r include=F}\n###Data Preparation\n\n####Load Relevant Libraries and Functions\nlibrary(tidyverse)\n#library(langcog)\nlibrary(stringr)\nlibrary(rjson)\nlibrary(coin)\n\nsem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}\nci95 <- function(x) {sem(x) * 1.96}\naddnas <- function (x) {if (length(x)==0){\n  result = NA\n} else {result = x}\n  return(result)\n}\n\n####Import data\n\npath <- \"D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/data/\"\nfiles <- dir(\"D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/data/anonymized-results/\", \n             pattern = \"*.json\")\nd.raw <- data.frame()\nNUM_TRIALS = 50\nfor (f in files) {\n  jf <- paste0(path, \"anonymized-results/\",f)\n  jd <- fromJSON(file = jf)\n  id <- data.frame(subid = f,\n                   adj = jd$answers$data$adj,\n                   verb = jd$answers$data$verb,\n                   noun = jd$answers$data$noun,\n                   dir = jd$answers$data$dir,\n                   num_checked = as.numeric(jd$answers$data$num_checked),\n                   quest_order = c(1:NUM_TRIALS),\n                   noun = jd$answers$data$noun,\n                   elapsed_ms = jd$answers$data$elapsed_ms,\n                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,\n                   workerid = jd$WorkerId,\n                   language = tolower(jd$answers$data$lang),\n                   gender = jd$answers$data$gender,\n                   prototype_status = jd$answers$data$prototype_status,\n                   non_consec = jd$answers$data$non_consecutive,\n                   is_endpoint = jd$answers$data$is_endpoint,\n                   endpoint = as.character(unlist(jd$answer$data$endpoint)),\n                   good_endpoint = jd$answers$data$good_ep,\n                   none_checked = jd$answer$data$none_checked,\n                   screen_size = as.numeric(jd$answer$data$screen_size))\n                    \n                  \n  d.raw <- bind_rows(d.raw, id)\n}\n\n# Number of participants\nlength(unique(d.raw$workerid))\nlength(unique(d.raw$subid))\ntable(d.raw$verb)/50\ntable(as.factor(d.raw$workerid[d.raw$verb=='are']))\nnum_trials = 48\n\nall.none.raw <- d.raw %>%\n  filter(adj != \"pretty\") %>%\n  filter(adj != \"ugly\")%>%\n  group_by(adj)%>%\n  summarise(all.c = sum(num_checked==7), none.c = sum(none_checked))\n\n#### Data exclusion / filtering\n```\n\n###Cleaning up unpredicted typos\n```{r}\ntable(as.factor(d.raw$language))\nfor (i in 1:length(d.raw$language)) {\n   if (d.raw$language[i] == \"ebglish\" & (!is.na(d.raw$language[i]))){\n   d.raw$language[i] = \"english\"\n   }\n }\n```\n###planned exclusions\n\n```{r}\n# get rid of training items, exclude non-English speakers, exclude those described below\n\nd <- filter(d.raw, prototype_status != \"na\") %>%\n  filter(verb == \"are\") %>%\n  filter(as.numeric(screen_size) >= 12) %>%\n  filter(str_detect(language, 'eng')) %>%\n  select(-language) %>%\n  group_by(subid) %>%\n  mutate(perc_non_consec = sum(non_consec)/num_trials,\n            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,\n         perc_good_endpoint = (sum(good_endpoint))/num_trials) %>%\n  filter(perc_non_consec < .1) %>%\n  filter(perc_good_endpoint >.9) %>%\n  filter(is_endpoint == TRUE) %>%\n  filter(good_endpoint == TRUE) %>%\n  filter(non_consec == FALSE)\nfor (i in 1:length(d$none_checked)) {\n   if (d$none_checked[i] == TRUE & (!is.na(d$none_checked[i]))){\n   d$num_checked[i] = 0\n   }\n }\n\nlength(unique(d$workerid))\ntable(as.factor(d$gender))/num_trials\n#for pilot A\n# d <- filter(d.raw, prototype_status != \"na\") %>%\n#   group_by(subid) %>%\n#   mutate(perc_non_consec = sum(non_consec)/num_trials,\n#             perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,\n#          perc_good_endpoint = (sum(good_endpoint))/num_trials) \n\n#need to check for having more than 10% non_consecutive or less than 90% with the right endpoint, and exclude those participants, and then exclude any remaining trials in which there is non_consecutive data or no endpoint.  (The option for saying none of them is big is coded as 9, so that if someone checks both the none box and one of the images then it comes up as non-consecutive)\n\nall.none <- d %>%\n  filter(adj != \"pretty\") %>%\n  filter(adj != \"ugly\")%>%\n  group_by(adj)%>%\n  summarise(all.c = sum(num_checked==7), none.c = sum(none_checked))\n\n\n\n\nhead(d)\n\n#### Prepare data for analysis - create columns etc.\n```\n\n### Confirmatory analysis\n#### Key test\n```{r}\n#The mean zone for each adjective -- equivalent to Table 1\nzones_table <- d %>%\n  group_by(verb, adj) %>%\n  summarise(mean_zone = mean(num_checked), sds = sd(num_checked))\n\nzones_table\n```\n\n![Table 1 from Tribushinina, comparing the mean number of items selected for each adjective](figures/trib-tab-1-mean-zones.png)\n\nThe  **key test** compares the size of the *big* zone and the *small* zone:\n```{r}\n#The key analysis -- testing whether the small zone is bigger than the big zone\nd_wilc <- d %>%\n  group_by(subid, verb, noun, adj, dir) %>%\n  summarise(zone = num_checked)%>%\n  spread(adj, zone)\n  wilcox.test(d_wilc$big, d_wilc$small, alternative = \"l\", paired = TRUE)\n  \n  \nwilcoxsign_test(d_wilc$big ~ d_wilc$small, distribution=\"exact\")\n\n\n```\n\nThis experiment succeeded in replicating the key result from Tribushinina (2011). The mean number of items checked as *small* was significantly larger than the mean number of items checked as *big*.\n\n####Differences between items of different prototypicality status for each adjective\n\n```{r}\n\nd_graph <- d %>%\n  group_by(prototype_status, adj) %>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n\n\n\ntable(d_graph$adj, d_graph$prototype_status)\nstr(d_graph)\n\nd_graph$adj <- factor(d_graph$adj)\nd_graph$prototype_status <- factor(d_graph$prototype_status)\nlevels(d_graph$prototype_status)\n\nlevels(d_graph$adj)\nlevels(d_graph$prototype_status)\n\n\nfriedman.test(mean_zone ~ adj | prototype_status, data = d_graph)\n\n#create graph equivalent to figure 2 -- mean number of items labeled for each adjective for each prototypicality status\n\nggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-sems, ymax=mean_zone+sems),\n                  width=.2, position=position_dodge(.9)) + ggtitle(\"Experiment 1a - cartoons ordered - Mean zone by prototype status\")\n\nggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9)) + ggtitle(\"Experiment 1a - cartoons ordered - Mean zone by prototype status\")\n\ntheme_set(theme_bw(base_size = 18))\n\n#graph for cogsci paper\npng(filename = \"fig-exp1-res.png\", width = 601, height = 373)\nprint(ggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + \n        geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis), width=.2, position=position_dodge(.9)) + \n      ggtitle(\"Mean zone by prototypicality status\") + \n      xlab(\"Adjecitve in the question\") +\n      scale_fill_brewer(name=\"Prot.\\nstatus\", breaks=c(\"big\", \"neither\", \"small\"),\n                         labels=c(\"Big\", \"Neutral\", \"Small\"), palette=\"YlGnBu\")+  \n     ylab(\"Mean num. of images selected\") + \n      theme(plot.title = element_text(lineheight=.8, face=\"bold\", hjust=0.5)) )\n\n\ndev.off()\n\n#graph for Semprag talk\npng(filename = \"semprag-fig-exp1-res.png\", width = 601, height = 373)\nprint(ggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + \n        geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis), width=.2, position=position_dodge(.9)) + \n      ggtitle(\"Mean zone by prototypicality status\") + \n      xlab(\"Adjecitve in the question\") +\n      scale_fill_discrete(name=\"Prot.\\nstatus\", breaks=c(\"big\", \"neither\", \"small\"),\n                         labels=c(\"Big\", \"Neutral\", \"Small\"))+  \n     ylab(\"Mean num. of images selected\") + \n      theme(plot.title = element_text(lineheight=.8, face=\"bold\", hjust=0.5)) )\n\n\ndev.off()\n```\n\n\n![Original graph of mean number of items checked for each adjective for each prototypicality group](figures/trib-fig-2.png)\n\nThis experiment succeeded in replicating the finding from Tribushinina (2011) that the *big* zone was bigger for prototypically small items than for prototypically big items or neutral items. Similarly, the *small* zone was found to be bigger for prototypically big items than for prototypically small items or neutral items.\n```{r}\n#graph without mice and chicks\nd_graph_nmc <- d %>%\n  filter((noun != \"mouse\")) %>%\n  filter(noun != \"chick\") %>%\n  group_by(prototype_status, adj) %>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n\nggplot(d_graph_nmc, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n```\n\n```{r}\nby_obj_s <- d %>%\n  filter(prototype_status == \"small\")%>%\n  group_by(noun, adj)%>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n#graph of mean number checked by object for the prototypically small objects\n\nggplot(by_obj_s, aes(x=adj, y=mean_zone, fill = noun)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n\n```\n\n```{r}\nby_obj_b <- d %>%\n  filter(prototype_status == \"big\")%>%\n  group_by(noun, adj)%>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n#graph of mean number checked by object for the prototypically big objects\n\nggplot(by_obj_b, aes(x=adj, y=mean_zone, fill = noun)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n\n```\n\n```{r}\nby_obj_n <- d %>%\n  filter(prototype_status == \"neither\")%>%\n  group_by(noun, adj)%>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n#graph of mean number checked by object for the objects neither prototypically small nor prototypically big\n\nggplot(by_obj_n, aes(x=adj, y=mean_zone, fill = noun)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n\n```\n```{r}\nby_obj_adjs <- d %>%\n  filter(adj == \"small\")%>%\n  group_by(noun, prototype_status)%>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n#graph of mean number checked by object when the adjective is *big*\n\nggplot(by_obj_adjs, aes(x=reorder(noun, mean_zone), y=mean_zone, fill=prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n\n```\n\n```{r}\nby_obj_adjb <- d %>%\n  filter(adj == \"big\")%>%\n  group_by(noun, prototype_status)%>%\n  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))\n#graph of mean number checked by object when the adjective is *big*\n\nggplot(by_obj_adjb, aes(x=reorder(noun, mean_zone), y=mean_zone, fill=prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),\n                  width=.2, position=position_dodge(.9))\n\n```\n\n\n```{r}\n# Friedman test of differences between objects of different prototypicality status when the adjective is big\nd_fried <- d %>%\n  filter(adj==\"big\")%>%\n  group_by(subid, prototype_status) %>%\n  summarise(zone = mean(num_checked))\n\n\n\ntable(d_fried$subid, d_fried$prototype_status)\nstr(d_fried)\n\nd_fried$subid <- factor(d_fried$subid)\nd_fried$prototype_status <- factor(d_fried$prototype_status)\nlevels(d_fried$prototype_status)\n\n\n\nlevels(d_fried$subid)\nlevels(d_fried$prototype_status)\n\n\nfriedman.test(zone ~ prototype_status  | subid, data = d_fried)\n```\n\n\n```{r}\n#test the difference between prototypically big and neutral objects when the adjective is big\nd_wilc_bn <- d %>%\n  filter(adj == \"big\")%>%\n  filter(prototype_status != \"small\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_bn$big, d_wilc_bn$neither, alternative = \"l\", paired = TRUE)\n\nwilcoxsign_test(d_wilc_bn$big ~ d_wilc_bn$neither, distribution=\"exact\")\n\nwrite.table(d_wilc_bn, \"D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/data/d_wilc_bn.txt\", sep=\"\\t\")\n\n\n```\n\n```{r}\n#test the difference between prototypically neither and small objects when the adjective is big\nd_wilc_ns <- d %>%\n  filter(adj == \"big\")%>%\n  filter(prototype_status != \"big\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_ns$neither, d_wilc_ns$small, alternative = \"l\", paired = TRUE)\nwilcoxsign_test(d_wilc_ns$neither ~ d_wilc_ns$small, distribution=\"exact\")\n```\n\n```{r}\n#test the difference between prototypically big and small objects when the adjective is big\nd_wilc_bs <- d %>%\n  filter(adj == \"big\")%>%\n  filter(prototype_status != \"neither\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_bs$big, d_wilc_bs$small, alternative = \"l\", paired = TRUE)\n\nwilcoxsign_test(d_wilc_bs$big ~ d_wilc_bs$small, distribution=\"exact\")\n```\n\n```{r}\n# Friedman test of differences between objects of different prototypicality status when the adjective is small\nd_fried_s <- d %>%\n  filter(adj==\"small\")%>%\n  group_by(subid, prototype_status) %>%\n  summarise(zone = mean(num_checked))\n\n\n\ntable(d_fried_s$subid, d_fried_s$prototype_status)\nstr(d_fried_s)\n\nd_fried_s$subid <- factor(d_fried_s$subid)\nd_fried_s$prototype_status <- factor(d_fried_s$prototype_status)\nlevels(d_fried_s$prototype_status)\n\nlevels(d_fried$subid)\nlevels(d_fried$prototype_status)\n\n\nfriedman.test(zone ~ prototype_status  | subid, data = d_fried_s)\n```\n\n\n```{r}\n#test the difference between prototypically big and neutral objects when the adjective is small\nd_wilc_sbn <- d %>%\n  filter(adj == \"small\")%>%\n  filter(prototype_status != \"small\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_sbn$big, d_wilc_sbn$neither, alternative = \"g\", paired = TRUE)\n\nwilcoxsign_test(d_wilc_sbn$big ~ d_wilc_sbn$neither, distribution=\"exact\")\n```\n\n```{r}\n#test the difference between prototypically neither and small objects when the adjective is small\nd_wilc_sns <- d %>%\n  filter(adj == \"small\")%>%\n  filter(prototype_status != \"big\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_sns$neither, d_wilc_sns$small, alternative = \"g\", paired = TRUE)\n\nwilcoxsign_test(d_wilc_sns$neither ~ d_wilc_sns$small, distribution=\"exact\")\n```\n\n```{r}\n#test the difference between prototypically big and small objects when the adjective is small\nd_wilc_sbs <- d %>%\n  filter(adj == \"small\")%>%\n  filter(prototype_status != \"neither\")%>%\n  group_by(subid, verb, prototype_status) %>%\n  summarise(zone = mean(num_checked))%>%\n  spread(prototype_status, zone)\n\nwilcox.test(d_wilc_sbs$big, d_wilc_sbs$small, alternative = \"g\", paired = TRUE)\n\nwilcoxsign_test(d_wilc_sbs$big ~ d_wilc_sbs$small, distribution=\"exact\")\n```\n\n####Reaction times by prototypicality status for each adjective\n\n```{r}\n#create equivalent of Figure 3 -- reaction times for each adjective for each prototypicality group\nd_graph <- d %>%\n  group_by(prototype_status, adj) %>%\n  summarise(mean_rt = mean(elapsed_first_click_ms), sems = sem(elapsed_first_click_ms), cis = ci95(elapsed_first_click_ms))\n\n\n\nd_graph$adj <- factor(d_graph$adj)\n\n\nlevels(d_graph$adj)\n\n\nggplot(d_graph, aes(x=adj, y=mean_rt, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_errorbar(aes(ymin=mean_rt-sems, ymax=mean_rt+sems),\n                  width=.2, position=position_dodge(.9))\n\nggplot(d_graph, aes(x=adj, y=mean_rt, fill = prototype_status)) + geom_bar(stat = \"identity\", position=position_dodge()) +\n    geom_text(aes(label=round(mean_rt,2)), vjust=7, position=position_dodge(width = 1)) +\n    geom_errorbar(aes(ymin=mean_rt-cis, ymax=mean_rt+cis),\n                  width=.2, position=position_dodge(.9))\n```\n\n![Original graph of reaction times for each adjective for each prototypicality group](figures/trib-fig-3-rts.png)\n\nThe reaction times that I found did not replicate the pattern found by Tribushinina. However, I have also used no exclusion criteria in examining them, and they may be overly influenced by outliers. \n\n```{r}\n#test the difference between RTs for prototypically big when the adjective is small and prototypically small objects when the adjective is big -- incompatible questions\n\nsmall_incomp <- d %>%\n  filter(adj == \"small\") %>%\n  filter(prototype_status == \"big\")\n\nbig_comp <- d %>%\n  filter(adj == \"big\") %>%\n  filter(prototype_status == \"big\")\n\nbig_incomp <- d %>%\n  filter(adj == \"big\") %>%\n  filter(prototype_status == \"small\")\n\nsmall_comp <- d %>%\n  filter(adj == \"small\") %>%\n  filter(prototype_status == \"small\") \n\n#wilcox.test(small_comp$elapsed_first_click_ms, small_incomp$elapsed_first_click_ms, alternative = \"g\", paired = TRUE)\n\n#wilcox.test(big_comp$elapsed_first_click_ms, big_incomp$elapsed_first_click_ms, alternative = \"g\", paired = TRUE)\n\n#same test using subject means instead of raw data (which can't relly be paired and also gives errors when trials are removed so there are unequal numbers in the groups) \nsmall_test <- d%>%\n  filter(adj == \"small\") %>%\n  filter(prototype_status != \"neither\") %>%\n  group_by(subid, verb, prototype_status) %>%\n  summarize(mean_rt = mean(elapsed_first_click_ms)) %>%\n  spread(prototype_status, mean_rt)\n\nwilcox.test(small_test$small, small_test$big, alternative = \"g\", paired = TRUE)\n\nbig_test <- d%>%\n  filter(adj == \"big\") %>%\n  filter(prototype_status != \"neither\") %>%\n  group_by(subid, verb, prototype_status) %>%\n  summarize(mean_rt = mean(elapsed_first_click_ms)) %>%\n  spread(prototype_status, mean_rt)\n\nwilcox.test(big_test$big, big_test$small, alternative = \"g\", paired = TRUE)\n\n\n\n```\n\n```{r}\n#test differnece between RTs for the adjective big and the adjective small, with the prediction that the processing of small is more cognitively demanding and therefore RTs should be longer. Tribushinina(2011) did not find a significant differnce.\nd_rt <- d %>%\n  group_by(subid, noun, dir, adj)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(adj, rt)\n\nwilcox.test(d_rt$small, d_rt$big, alternative = \"g\", paired = TRUE)\n```\n\nSurprisingly, although Tribushinina found no effect of adjective on the processing time, despite the prediction that *small* is more cognitively demanding than *big*, I did find the predicted effect.\n\n```{r}\n#test of difference between RTs on ascending and descending trials with the same adjective\nd_rt_small <- d %>%\n  filter(adj == \"small\") %>%\n  group_by(subid, noun, dir)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(dir, rt)\n\nwilcox.test(d_rt_small$asc, d_rt_small$desc, alternative = \"l\", paired = TRUE)\n\nd_rt_big <- d %>%\n  filter(adj == \"big\") %>%\n  group_by(subid, noun, dir)%>%\n  summarise(rt = elapsed_first_click_ms) %>%\n  spread(dir, rt)\n\nwilcox.test(d_rt_big$asc, d_rt_big$desc, alternative = \"l\", paired = TRUE)\n```\n\n\n## Discussion\nThe main finding from Tribushinina (2011) was that the *big* zone was smaller than the *small* zone. This finding replicated. I found that the mean number of items marked *big* was `r round(zones_table[1,3], 2)` (SD = `r round(zones_table[1,4], 2)`) whereas the mean number of items marked *small* was `r round(zones_table[2,3], 2)` (SD = `r round(zones_table[2,4], 2)`). A Wilcoxon test showed that the *small* is significantly larger than the *big* zone. Additionally, the distinctions between prototypically big, prototypically small and neither items found by Tribushinina also were replicated in this experiment. However, the RT findings did not replicate in a straightforward manner. It is possible that if the data were processed more and outliers removed then the picture might be different.\n\n### Summary of Replication Attempt\n\nOverall, the replication was successful. the main findings in Tribushinina (2011) replicated nicely, despite the change in language and the change in setting.  \n\n### Commentary\n\nI find it interesting that despite problematic stimuli (e.g. the picture of a house, meant to be a prototypically big item is a gingerbread house) and problematic methodology (e.g. no fillers, set up in a way that encourages the development of a strategy) the findings still replicated so nicely. This raises interesting questions regarding how people treat the visual representations given them. Is it enough that the linguistic stimulus said \"Which *houses* are big?\" for people to treat the images as generic houses despite the picture encouraging an interpretation of a much smaller house?\n",
    "created" : 1530108392048.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1288523114",
    "id" : "C71936DF",
    "lastKnownWriteTime" : 1525299536,
    "last_content_update" : 1525299536,
    "path" : "D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/writeup/Replication-Report.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}